---
title: "Reburn analysis"
author: "CT"
date: "2022-11-30"
output: html_document
---


This script cleans and analyzes data for reburn analyses.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)





library(randomForest)
library(ranger) #a faster version of the RF algorithm
library(pdp)# for partial dependence plots (PDPs)

library(tidyverse)
library(here)
library(sp)
library(sf)
library(terra)
library(raster)

library(mgcv)
library(tidymv)

data_dir = readLines(here("data_dir_D.txt"), n=1)
source(here("scripts/convenience_functions.R"))

```

Load reburn points for analysis

```{r}
data = st_read(datadir("prelim-outputs/points/points_for_analysis_1-13.3-23.gpkg"))  

#add lat long coordinates to data frame
data_wgs = st_transform(data, 4326)
coords = data.frame(st_coordinates(data_wgs))

data$lat = coords$Y
data$long = coords$X
```

### Prep data for spatial partioning into test and training datasets 
> backwards selection
> mumin
> RF for important predictors, spatial zone splitting? 

Assign each point to spatial sampling zone 12km
```{r}
#determine data extent
extent(data)
# plot(extent)
e = ext(c(-2280909, -626619.3, 1007070, 3117660)) #xmin, xmax, ymin, ymax extent of data
p = as.polygons(e) #covert to polygons
crs(p) = crs(data) #set crs

r = rast(p) #convert raster

zones = rast(p, resolution = c(12000, 12000))
values(zones) = 1:ncell(zones)

# plot(zones)

#extract zone value to points
data$sample_zones = extract(zones, data, ID=FALSE)

#get rid of ID var in sample zones 
data = data %>% mutate(sample_zones = sample_zones$lyr.1) 

```

# Select points for analysis based on following criteria:

- Not on FS land (focus analysis on forested FS land, and for management)
- Less than 25% tree cover at time of reburn (focus analysis on forested areas)
- second fire occurred before 2002 (limited by MODIS for day of fire weather)
- burned at <0.5 CBI in initial or reburn fires (remove unburned areas to limit residual error where fire did not make it to a point within a fire perimeter)

```{r}

#remove points that... 
data_sub = data %>% 
  filter(tree_reburn >= 40 & #have greater than 40% tree cover at time of reburn
           mostrecent > 2001 & #second fire occurred after 2001 (for MODIS weather data)
           cbi_initial > 0.5 & #burned at >0.5 CBI in initial or reburn fires (remove unburned areas to limit residual error
           cni85_21 > 0.5) %>%
  filter(!is.na(ecoregion)) #remove points that fall outside of our 4 ecoregions


# st_write(data_sub, datadir("/prelim-outputs/points/data_sub_1-12-23.gpkg"))
```

add in erc percentiles
```{r}
#add missing data 
#add weather percentiles for erc, vs, and vpd 
perc_w = read_sf(datadir("prelim-outputs/points/dob_percentiles_1-12-23.gpkg"))

data_sub1 = st_join(data_sub, perc_w[,c("erc_perc","vpd_perc","vs_perc")])
```

clean data
```{r}
#clean data
data_sub2 = data_sub1 %>% 
  rename(cbi_reburn = cni85_21) %>% data.frame() %>%
  #remove rows where ndvi = NA (29 rows) 
  drop_na(ndvi) %>%
 
  #lump wildfire codes
  mutate(reburn_fire_type = recode(reburn_fire_type, 'Unknown' = 'Wildfire', 'Wildfire Daily Fire Perimeter' = 'Wildfire', 'Wildfire Final Fire Perimeter' = 'Wildfire', 'Wildland Fire Use' = 'Wildfire'),
  initial_fire_type = recode(initial_fire_type, 'Unknown' = 'Wildfire', 'Wildfire Daily Fire Perimeter' = 'Wildfire', 'Wildfire Final Fire Perimeter' = 'Wildfire', 'Wildland Fire Use' = 'Wildfire'),
  ecoregion = as.factor(ecoregion)) %>%
  
  #remove 8 points with no weather data 
  filter(fm100_02_2 >0 & th_02_21 > 0 & vpd_02_21 > 0 &  fm1000_02_ > 0 & vs_02_21 > 0 &  erc_02_21 > 0) %>%
  
  #remove 122 points without AET data
  filter(AET > 0) %>%
  
  #set point id to row names 
  column_to_rownames(., 'pointid')
  

#clean up facts management data
data_facts = data_sub2 %>%
    #lump facts management into one variable (time since management)
  mutate(time2manage1 = pmin(pfire_yrs2reburn, mechanical_yrs2reburn, na.rm = TRUE),
  #set NAs to time since last fire
        time2manage = coalesce(time2manage1, time_betwe),
  #add logical variable for if a point was managed within 10 years of the reburn
        postmanage10 = time2manage1 <= 10,
        postmanage10 = coalesce(postmanage10, FALSE),
    #add logical variable for if a point was managed within 10 years of the initial fire
        time2manage_preburn = pmin(pfire_yrs2initial, mechanical_yrs2initial, na.rm = TRUE),
        premanage10 = time2manage_preburn <= 10,
        premanage10 = coalesce(premanage10, FALSE)) #set NBAs to FALSE


  
data_clean = data_facts %>%
  #rescale time between to decades
  mutate(time_betwe = time_betwe/10) %>%
  #remove unnecessary columns
  dplyr::select(-c(LC20_Elev_, geom, grid_code, secondrece, max_yr_mechanical, max_yr_preburn_mechanical, max_yr_pfire, max_yr_preburn_pfire, pfire_yrs2reburn, pfire_yrs2initial, count_trt, count_trt_pfire, count_trt_mechanical, mechanical_yrs2reburn, mechanical_yrs2initial, count_trt_preburn, time2manage1, time2manage_preburn)) 

#write out cleaned_data
# st_write(data_clean,datadir("prelim-outputs/points/data_clean_for_analaysis.gpkg"))

#remove rows that were managed between initial and reburn (save these for a separate analyis)
data_nomanage = data_clean %>% filter(postmanage10 == FALSE)


#subsample large fires (max points per fire = 1000)
# data_subsample1 = data_nomanage %>%
#   group_by(reburn_fireID) %>%
#   mutate(count_points_reburn = n()) %>%
#   filter(count_points_reburn > 1128) %>% #median count
#   slice_sample(n = 1128)

# summary(data_subsample1$count_points_reburn)

# data_subsample2 = data_nomanage %>%
#   group_by(reburn_fireID) %>%
#   mutate(count_points_reburn = n()) %>%
#   filter(count_points_reburn <= 1128)
# 
# data_subsample = bind_rows(data_subsample1, data_subsample2)
  

#break into low, moderate, and high initial fire severity categories
data_low = data_nomanage %>%
  filter(cbi_initial < 1.5)

data_mod = data_nomanage %>%
  filter(cbi_initial >= 1.5 & cbi_initial < 2.5)

data_high = data_nomanage %>% 
  filter(cbi_initial >= 2.5)

data_lowmod = data_nomanage %>%
  filter(cbi_initial < 2.5)
```

Explore data
```{r}

ggplot(data = data_lowmod, aes(x = reburn_fire_size, fill = ecoregion))+
  geom_histogram()+
  xlab("reburn total fire size (ac)")

t = data_lowmod %>% 
  mutate(unique_fireid = paste(initial_fireID, reburn_fireID)) %>%
           group_by(unique_fireid) %>%
  mutate(mean_cbi = mean(cbi_reburn),
            count_points_fire = n()) %>%
  ungroup()

t_reburn = data_lowmod %>% 
           group_by(reburn_fireID) %>%
  mutate(mean_cbi = mean(cbi_reburn),
         mean_time_between = mean(time_betwe),
            count_points_reburn = n()) %>%
  ungroup()


t2 = t %>% filter(count_points_fire > 1500) %>% group_by(unique_fireid) %>% summarise(count = n())
t3 = t_reburn %>% filter(count_points_reburn > 1500) %>% group_by(reburn_fireID) %>% summarise(count = n())


ggplot(data = data_lowmod, aes(x = mostrecent, y = cbi_reburn, color = ecoregion))+
  geom_jitter(alpha = 0.2)+
  geom_smooth()

ggplot(data = t, aes(x = count_points_fire, y = mean_cbi, color = ecoregion))+
  geom_jitter(alpha = 0.2)+
  geom_smooth()+
  theme_bw()

ggplot(data = t_reburn, aes(x = log10(count_points_reburn), y = mean_cbi, color = ecoregion))+
  geom_jitter(alpha = 0.2)+
  xlab("log 10 count of points in reburn fire") +
  geom_smooth(method = 'lm')+
  geom_smooth(formula = y ~ s(x, bs = "cs", k = 4))+
  theme_bw()

ggplot(data = t_reburn, aes(x = log10(count_points_reburn), y = mean_time_between, color = ecoregion))+
  geom_jitter(alpha = 0.2)+
  xlab("log 10 count of points in reburn fire") +
  # geom_smooth(method = 'lm')+
  geom_smooth(formula = y ~ s(x, bs = "cs", k = 4))+
  theme_bw()
```

### Split data into train and test


Partition data to test and train sets stratified by sample zones 
```{r}
library(splitTools) #https://cran.r-project.org/web/packages/splitTools/vignettes/splitTools.html
library(ranger)

set.seed(222)

# Split into training and test stratified by sample zones

inds = partition(data_lowmod$sample_zones, p = c(train = 0.7, test = 0.3))
str(inds)

train <- data_lowmod[inds$train, ]
test <- data_lowmod[inds$test, ]

# Get stratified cross-validation in-sample indices
folds <- create_folds(train$sample_zones, k = 5)


```

Repeated cross-validation


If feasible, repeated cross-validation is recommended in order to reduce uncertainty in decisions. The process is the same as above. Instead of getting five performance values per fold, we get five times the number of repetitions (here, three).
```{r}
# # We start by making repeated, stratified cross-validation folds
# folds <- create_folds(train$Sepal.Length, k = 5, m_rep = 3)
# length(folds)
# 
# 
# for (i in seq_along(valid_mtry)) {
#   cv_mtry <- numeric()
#   for (fold in folds) {
#     fit <- ranger(Sepal.Length ~ ., data = train[fold, ], mtry = i)
#     cv_mtry <- c(cv_mtry, 
#                  rmse(train[-fold, "Sepal.Length"], predict(fit, train[-fold, ])$predictions))
#   }
#   valid_mtry[i] <- mean(cv_mtry)
# }
# 
# # Result of cross-validation
# valid_mtry
# 
# (best_mtry <- which.min(valid_mtry))
# 
# 
# # Use optimal mtry to make model
# final_fit <- ranger(Sepal.Length ~ ., data = train, mtry = best_mtry)
# rmse(test$Sepal.Length, predict(final_fit, test)$predictions)


```



### Explore correlations between variables
```{r}
library(purrr)

#keep only numeric variables
data_num = data_lowmod %>%
  keep(is.numeric)

# library(PerformanceAnalytics)
# cor(data_num, method = "pearson", use = "complete.obs")
# chart.Correlation(cor(data_num))

weather = test %>% dplyr::select(erc_02_21, vs_02_21, th_02_21, fm1000_02_, fm100_02_2, vpd_02_21, cbi_reburn, cbi_initial)

clim_topo = test %>% dplyr::select(heat_load, PRISM_tmea, PRISM_ppt_, PRISM_vpdm, AET, ndvi, shrub_rebrn, tree_reburn, TPI_1024, cbi_reburn, cbi_initial, time_betwe)

firehist = test %>% dplyr::select(time_betwe, postmanage10, premanage10, count_burn, cbi_reburn, cbi_initial)
```

Plot relationships
```{r}
library(GGally)
# ggpairs(weather, ggplot2::aes(colour=ecoregion))
ggpairs(weather)
ggpairs(clim_topo)
ggpairs(firehist)
```



#### Explore indiviual variable relationships with cbi reburn
```{r}

data_lowmod %>%
  dplyr::select(-c(reburn_fire_type, initial_fire_type, initial_fireID, reburn_fireID, postmanage10, premanage10, sample_zones, lat, long, LC16_BPS_2, count_trt_preburn_mechanical, count_trt_preburn_pfire, time2manage)) %>%
  pivot_longer(!c(cbi_reburn, ecoregion), names_to = "key", values_to = "value") %>% #convert to long format for fast plotting
  ggplot(aes(x = value, y = cbi_reburn, color = ecoregion)) +
  facet_wrap(~ key, scales = "free") +
  geom_smooth(formula = y ~ s(x, bs = "cs", k = 3)) +
  theme_bw(13)



# data_lowmod %>%
#   ggplot(aes(x = shrub_rebrn, y = ndvi, color = ecoregion)) +
#   geom_smooth(formula = y ~ s(x, bs = "cs", k = 4)) +
#   theme_bw(13)
# 
# data_lowmod %>%
#   ggplot(aes(x = tree_reburn, y = ndvi, color = ecoregion)) +
#   geom_smooth(formula = y ~ s(x, bs = "cs", k = 4)) +
#   theme_bw(13)
  
```


#### Logistic tranform "reburn cbi" response variable because its bounded 0.5-3 
>not sure if we need to do this if using GAMs?

```{r}
#functions to normalize and logit transform response var
normalize <- function(x) {
return ((x - 0.5) / (3.01 - 0.5)) #severity range = 0.5-3 (a few observations have severity = 3 so setting upper bound to 3.01)
}

logit <- function(x) {
  return(
    log(x/(1-x))
  )
}

```


model relationships with transformed response variable - CBI
```{r}

#scale reburn CBI from 0-1
test$cbi_reburn_scale = normalize(test$cbi_reburn) 



# plot logit models
test %>%
  dplyr::select(-c(reburn_fire_type, initial_fire_type, initial_fireID, reburn_fireID, count_trt_preburn_mechanical, count_trt_preburn_pfire, cbi_reburn, LC16_BPS_2)) %>%
  pivot_longer(!c(cbi_reburn_scale, ecoregion), names_to = "key", values_to = "value") %>% #convert to long format for fast plotting
  ggplot(aes(x = value, y = logit(cbi_reburn_scale), color = ecoregion)) +
  facet_wrap(~ key, scales = "free") +
  geom_point(alpha = 0.1)+
    geom_smooth(formula = y ~ s(x, bs = "cs")) +
  theme_bw(13)

test %>%
  dplyr::select(-c(reburn_fire_type, initial_fire_type, initial_fireID, reburn_fireID, count_trt_preburn_mechanical, count_trt_preburn_pfire, cbi_reburn, LC16_BPS_2, postmanage10, premanage10)) %>%
  pivot_longer(!c(cbi_reburn_scale, ecoregion), names_to = "key", values_to = "value") %>% #convert to long format for fast plotting
  ggplot(aes(x = value, y = logit(cbi_reburn_scale), color = ecoregion)) +
  facet_wrap(~ key, scales = "free") +
    geom_smooth(formula = y ~ s(x, bs = "cs", k = 3)) +
  theme_bw(13)
```



### Fit separate models for each ecoregion and scale predictors

```{r}
#scale numeric predictors for model fit - don't scale time between t or cbi or erc percentiles to maintain interpretation
allpreds = c("heat_load", "cbi_reburn", "count_burn", "time_betwe", "PRISM_tmea", "PRISM_ppt_", "TPI_1024",
                "LC16_BPS_2", "fm100_02_2", "th_02_21", "vpd_02_21", "vs_02_21",
                "erc_02_21", "PRISM_vpdm",  "AET", "fm1000_02_", "ndvi", "shrub_rebrn",
                "tree_reburn", "afg_rebrn", "pfg_rebrn", "cbi_initial", "ecoregion",
                "count_trt_preburn_mechanical", "count_trt_preburn_pfire", "reburn_fire_type",
                "reburn_fireID", "initial_fire_type", "initial_fireID", "lat",
                "long",  "sample_zones", "erc_perc", "vpd_perc",  "vs_perc", "time2manage", 
                "postmanage10", "premanage10")

preds_not2scale = c("cbi_reburn", "cbi_initial", "time_betwe", "ecoregion", "erc_perc", "vpd_perc",  "vs_perc",
                "count_trt_preburn_mechanical", "count_trt_preburn_pfire", "reburn_fire_type",
                "reburn_fireID", "initial_fire_type", "initial_fireID", "lat",
                "long",  "sample_zones", "time2manage", 
                "postmanage10", "premanage10") #, "count_points_reburn"

scale_df = function(df){
  data_scale = scale(df[!(names(df) %in% preds_not2scale)], scale = TRUE, center = TRUE)
  data_scale_all = cbind(data_scale, df[names(df) %in% preds_not2scale])
  return(data_scale_all)
}

#create new dfs for each ecoregion and scale each ecoregion separately 
data_lowmod_ca = data_lowmod %>% filter(ecoregion == "California Coast") %>%
  scale_df()

data_lowmod_nm = data_lowmod %>% filter(ecoregion == "Northern Mountains") %>%
  scale_df()

data_lowmod_sw = data_lowmod %>% filter(ecoregion == "Southwest") %>%
  scale_df()

data_lowmod_wm = data_lowmod %>% filter(ecoregion == "Western Mountains") %>%
  scale_df()

```

Test for spatial autocorrelation
```{r}
library(ape)
inv_dist = with(data_lowmod_sw, 1/dist(cbind(lat, long), diag = TRUE, upper = TRUE))
inv_dist = as.matrix(inv_dist)
ape::Moran.I(data_lowmod_sw$cbi_reburn, weight = inv_dist, scaled = TRUE)

#observed = 0.16  - CA; 0.14 - NM; 0.23 for SW
# While statistically significant, there actually isnâ€™t too much going on, though it may be enough to warrant dealing with in some fashion.

```


Model fit/selection with mgcv 
>https://stat.ethz.ch/R-manual/R-devel/library/mgcv/html/gam.selection.html 
>https://stats.stackexchange.com/questions/519433/gam-and-multiple-continuous-continuous-interactions-tensor-smooths #helpful for interpretting and fitting interactions (ti vs te vs s)

>all about gams: https://m-clark.github.io/generalized-additive-models/application.html#gam-1

```{r}
# gm = function(df){
#   
#   #fit gam - removed fm100 & fm1000, reburn shrub cover, ndvi, and management 
#   gamfit = gam(cbi_reburn ~ count_burn + #not logit transformed response
#                   s(AET, k = 5, bs = "cs") +
#                   # s(PRISM_ppt_, k = 5, bs = "cs") +
#                   # s(PRISM_tmea, k = 5, bs = "cs") +
#                   # s(PRISM_vpdm, k = 5, bs = "cs") +
#                   s(cbi_initial, k = 5, bs = "cs") +
#                   s(time_betwe, k = 5, bs = "cs") +
#                   s(erc_perc, k = 5, bs = "cs") +
#                   s(vs_perc, k = 5, bs = "cs") +
#                   s(vpd_perc, k = 5, bs = "cs") +
#                   s(afg_rebrn, k = 5, bs = "cs") +
#                   s(pfg_rebrn, k = 5, bs = "cs") +
#                   # s(erc_02_21, k = 5, bs = "cs") +
#                   # s(th_02_21, k = 5, bs = "cs") +
#                   # s(vpd_02_21, k = 5, bs = "cs") +
#                   # s(vs_02_21, k = 5, bs = "cs") +
#                   s(heat_load, k = 5, bs = "cs") +
#                   s(TPI_1024, k = 5, bs = "cs") +
#                   # s(ndvi, k = 5, bs = "cs") +
#                   # s(tree_reburn, k = 5, bs = "cs") +
#                   ti(time_betwe, by = AET, k = 5, bs = "cs") +
#                   # ti(time_betwe, by = PRISM_ppt_, k = 5, bs = "cs") +
#                   # ti(time_betwe, by = PRISM_tmea, k = 5, bs = "cs") +
#                   ti(time_betwe, by = vpd_perc, k = 5, bs = "cs") +
#                   ti(time_betwe, by = vs_perc, k = 5, bs = "cs") +
#                   ti(time_betwe, by = erc_perc, k = 5, bs = "cs") +
#                  #account for spatial autocorrelation
#                  s(long, lat, bs = 'gp', k = 100, m = 2), #Using the Gaussian process smooth produces a result that is akin to kriging. There are many other features to play with, as well as other bases that would be applicable
#                  #account for autocorrelation
#                   # s(long, lat, ),
#                 data = df,
#              select = T) 
# 
#   return(gamfit)
# 
# }

gm_prism = function(df, k){
  
  #fit gam - removed fm100 & fm1000, reburn shrub cover, ndvi, and management 
  gamfit = bam(cbi_reburn ~ count_burn + #not logit transformed response
                  # s(AET, k = k, bs = "cs") +
                  # s(count_points_reburn, k = k, bs = "cs")+
                  s(PRISM_ppt_, k = k, bs = "cs") +
                  s(PRISM_tmea, k = k, bs = "cs") +
                  # s(PRISM_vpdm, k = k, bs = "cs") +
                  s(cbi_initial, k = k, bs = "cs") +
                  s(time_betwe, k = k, bs = "cs") +
                  s(erc_perc, k = k, bs = "cs") +
                  s(vs_perc, k = k, bs = "cs") +
                  s(vpd_perc, k = k, bs = "cs") +
                  # s(afg_rebrn, k = 5, bs = "cs") +
                  # s(pfg_rebrn, k = 5, bs = "cs") +
                  s(heat_load, k = k, bs = "cs") +
                  s(TPI_1024, k = k, bs = "cs") +
                  # s(ndvi, k = k, bs = "cs") +
                  # s(tree_reburn, k = k, bs = "cs") +
                  # ti(time_betwe, by = AET, k = k, bs = "cs") +
                  ti(time_betwe, by = PRISM_ppt_, k = k, bs = "cs") +
                  ti(time_betwe, by = PRISM_tmea, k = k, bs = "cs") +
                  ti(time_betwe, by = vpd_perc, k = k, bs = "cs") +
                  ti(time_betwe, by = vs_perc, k = k, bs = "cs") +
                  ti(time_betwe, by = erc_perc, k = k, bs = "cs") +
                 ti(time_betwe, by = cbi_initial, k = k, bs = "cs") +
                 # ti(time_betwe, by = count_points_reburn, k = k, bs = "cs") +
                 #account for spatial autocorrelation
                 s(long, lat, bs = 'gp', k = 100, m = 2), #Using the Gaussian process smooth produces a result that is akin to kriging. There are many other features to play with, as well as other bases that would be applicable
                 # correlation = corSpatial(form = ~ lon + lat, type = 'gaussian'),
                data = df,
             select = T,
             method = "fREML") 

  return(gamfit)

}


# gm_all_climate = function(df, k){
#   
#   #fit gam - removed fm100 & fm1000, reburn shrub cover, ndvi, and management 
#   gamfit = gam(cbi_reburn ~ count_burn + #not logit transformed response
#                   s(AET, k = k, bs = "cs") +
#                   s(PRISM_ppt_, k = k, bs = "cs") +
#                   s(PRISM_tmea, k = k, bs = "cs") +
#                   # s(PRISM_vpdm, k = k, bs = "cs") +
#                   s(cbi_initial, k = k, bs = "cs") +
#                   s(time_betwe, k = k, bs = "cs") +
#                   s(erc_perc, k = k, bs = "cs") +
#                   s(vs_perc, k = k, bs = "cs") +
#                   s(vpd_perc, k = k, bs = "cs") +
#                   s(afg_rebrn, k = 5, bs = "cs") +
#                   s(pfg_rebrn, k = 5, bs = "cs") +
#                   s(heat_load, k = k, bs = "cs") +
#                   s(TPI_1024, k = k, bs = "cs") +
#                   # s(ndvi, k = k, bs = "cs") +
#                   # s(tree_reburn, k = k, bs = "cs") +
#                   ti(time_betwe, by = AET, k = k, bs = "cs") +
#                   ti(time_betwe, by = PRISM_ppt_, k = k, bs = "cs") +
#                   ti(time_betwe, by = PRISM_tmea, k = k, bs = "cs") +
#                   ti(time_betwe, by = vpd_perc, k = k, bs = "cs") +
#                   ti(time_betwe, by = vs_perc, k = k, bs = "cs") +
#                   ti(time_betwe, by = erc_perc, k = k, bs = "cs") +
#                  #account for spatial autocorrelation
#                  s(long, lat, bs = 'gp', k = 100, m = 2), #Using the Gaussian process smooth produces a result that is akin to kriging. There are many other features to play with, as well as other bases that would be applicable
#                 data = df,
#              select = T) 
# 
#   return(gamfit)
# 
# }
```

Examine model fits
```{r}
#just aet for climate
fit_ca = gm(data_lowmod_ca)
fit_nm = gm(data_lowmod_nm)
fit_sw = gm(data_lowmod_sw)
fit_wm = gm(data_lowmod_wm)

#all climate vars (AET, precip and temp)
fit2_ca = gm_all_climate(data_lowmod_ca)
fit2_nm = gm_all_climate(data_lowmod_nm)
fit2_sw = gm_all_climate(data_lowmod_sw)
fit2_wm = gm_all_climate(data_lowmod_wm)

#not aet, includes prism temp/precip
fit3_ca = gm_prism(data_lowmod_ca, k = 4)
fit3_nm = gm_prism(data_lowmod_nm, k = 4)
fit3_sw = gm_prism(data_lowmod_sw, k = 4)
fit3_wm = gm_prism(data_lowmod_wm, k = 4)

#compare model fits
anova.gam(fit2_ca, fit_ca, test = "Chisq") 
anova.gam(fit2_wm, fit_wm, test = "Chisq")
anova.gam(fit2_sw, fit_sw, test = "Chisq")
anova.gam(fit2_nm, fit_nm, test = "Chisq")

anova.gam(fit2_ca, fit3_ca, test = "Chisq") 
anova.gam(fit2_wm, fit3_wm, test = "Chisq")
anova.gam(fit2_sw, fit3_sw, test = "Chisq")
anova.gam(fit2_nm, fit3_nm, test = "Chisq")
#not much difference between full models and models without AET. Much larger differences when precip and temp are removed and AET is kept
```


CBI predictions
```{r}
library(tidymv)

cbi_preds_func = function(gam_fit, df){
  preds = predict_gam(gam_fit, length_out = 30, values = list(PRISM_ppt_ = 0, PRISM_tmea = 0, cbi_initial =c(0.51, 1.5, 2.49), time_betwe = seq(0.1, 3.6, by = 0.1), erc_perc = .9, vs_perc = .5, vpd_perc = .9, heat_load = 0, TPI_1024 = 0, count_burn = 2, long = mean(df$long), lat = mean(df$lat))) #exclude_terms = "s(long,lat)") #count_points_reburn = seq(1, 2000, by = 10))
  return(preds)
}

ca_preds = cbi_preds_func(fit3_ca, data_lowmod_ca)
sw_preds = cbi_preds_func(fit3_sw, data_lowmod_sw)
nm_preds = cbi_preds_func(fit3_nm, data_lowmod_nm)
wm_preds = cbi_preds_func(fit3_wm, data_lowmod_wm)


plot_preds = function(preds){
  
  plot = preds %>%
  ggplot(aes(time_betwe, fit)) +
    geom_smooth_ci(cbi_initial, size = 1.05, legend = NA)+
    scale_color_manual(values= c("lightseagreen", "sienna1", "tomato3")) +
    scale_linetype_manual(values =c(1,2,3))+
  theme_bw(13) +
  theme(legend.title = element_blank())
  ylim(0.5, 3)
  
  return(plot)
}

library(gridExtra)
pca = plot_preds(ca_preds) + ggtitle("California coast")
psw = plot_preds(sw_preds) + ggtitle("Southwest")
pnm = plot_preds(nm_preds) + ggtitle("Northern Mountains")
pwm = plot_preds(wm_preds) + ggtitle("Western Mountains")

grid.arrange(pca, psw, pnm, pwm, nrow= 2, ncol=2)
```


wind speed predictions
```{r}
#predict for different wind speeds
vs_preds_func = function(gam_fit, df){
  preds = predict_gam(gam_fit, length_out = 30, values = list(PRISM_ppt_ = 0, PRISM_tmea = 0, cbi_initial= 1.5, time_betwe = seq(0.1, 3.6, by = 0.1), erc_perc = .9, vs_perc = c(0.3, 0.6, 0.95), vpd_perc = .9, heat_load = 0, TPI_1024 = 0, count_burn = 2, long = mean(df$long), lat = mean(df$lat))) #exclude_terms = "s(long,lat)") #count_points_reburn = seq(1, 2000, by = 10))
  return(preds)
}

ca_preds = vs_preds_func(fit3_ca, data_lowmod_ca)
sw_preds = vs_preds_func(fit3_sw, data_lowmod_sw)
nm_preds = vs_preds_func(fit3_nm, data_lowmod_nm)
wm_preds = vs_preds_func(fit3_wm, data_lowmod_wm)


plot_preds = function(preds){
  
  plot = preds %>%
  ggplot(aes(time_betwe, fit)) +
    geom_smooth_ci(vs_perc, size = 1.05, legend = NA)+
    scale_color_manual(values= c("lightseagreen", "sienna1", "tomato3")) +
    scale_linetype_manual(values =c(1,2,3))+
  theme_bw(13) +
  theme(legend.title = element_blank())
  ylim(0.5, 3)
  
  return(plot)
}

library(gridExtra)
pca = plot_preds(ca_preds) + ggtitle("California coast")
psw = plot_preds(sw_preds) + ggtitle("Southwest")
pnm = plot_preds(nm_preds) + ggtitle("Northern Mountains")
pwm = plot_preds(wm_preds) + ggtitle("Western Mountains")

grid.arrange(pca, psw, pnm, pwm, nrow= 2, ncol=2)
```

precip predictions
```{r}
#predict for different wind speeds
ppt_preds_func = function(gam_fit, df){
  preds = predict_gam(gam_fit, length_out = 30, values = list(PRISM_ppt_ = c(round(quantile(df$PRISM_ppt_, 0.20),2), round(quantile(df$PRISM_ppt_, 0.5),2), round(quantile(df$PRISM_ppt_, 0.90),2)), PRISM_tmea = 0, cbi_initial= 1.5, time_betwe = seq(0.1, 3.6, by = 0.1), erc_perc = .9, vs_perc = .5, vpd_perc = .9, heat_load = 0, TPI_1024 = 0, count_burn = 2, long = mean(df$long), lat = mean(df$lat))) #exclude_terms = "s(long,lat)") #count_points_reburn = seq(1, 2000, by = 10))
  return(preds)
}

ca_preds = ppt_preds_func(fit3_ca, data_lowmod_ca)
sw_preds = ppt_preds_func(fit3_sw, data_lowmod_sw)
nm_preds = ppt_preds_func(fit3_nm, data_lowmod_nm)
wm_preds = ppt_preds_func(fit3_wm, data_lowmod_wm)


plot_preds = function(preds){
  
  plot = preds %>%
  ggplot(aes(time_betwe, fit)) +
    geom_smooth_ci(PRISM_ppt_, size = 1.05, legend = NA)+
    scale_color_manual(values= c("lightseagreen", "sienna1", "tomato3")) +
    scale_linetype_manual(values =c(1,2,3))+
  theme_bw(13) +
  theme(legend.title = element_blank())
  ylim(0.5, 3)
  
  return(plot)
}

pca = plot_preds(ca_preds) + ggtitle("California coast")
psw = plot_preds(sw_preds) + ggtitle("Southwest")
pnm = plot_preds(nm_preds) + ggtitle("Northern Mountains")
pwm = plot_preds(wm_preds) + ggtitle("Western Mountains")

grid.arrange(pca, psw, pnm, pwm, nrow= 2, ncol=2)
```












```{r}
vis.gam(fit3_ca, view=c('time_betwe', 'cbi_initial'), n.grid=50, theta=30, phi=32, zlab="", too.far=0.1)+title("california coast")
vis.gam(fit3_nm, view=c('time_betwe', 'cbi_initial'), n.grid=50, theta=30, phi=32, zlab="", too.far=0.1)+title("northern mountains")
vis.gam(fit3_wm, view=c('time_betwe', 'cbi_initial'), n.grid=50, theta=30, phi=32, zlab="", too.far=0.1)+title("western mountains")
vis.gam(fit3_sw, view=c('time_betwe', 'cbi_initial'), n.grid=50, theta=30, phi=32, zlab="", too.far=0.1)+title("southwest")

vis.gam(fit3_ca, view=c('time_betwe', 'count_points_reburn'), n.grid=50, theta=50, phi=32, zlab="", too.far=0.1)+title("california coast")
vis.gam(fit3_nm, view=c('time_betwe', 'count_points_reburn'), n.grid=50, theta=30, phi=32, zlab="", too.far=0.1)+title("northern mountains")
vis.gam(fit3_wm, view=c('time_betwe', 'count_points_reburn'), n.grid=50, theta=30, phi=32, zlab="", too.far=0.1)+title("western mountains")
vis.gam(fit3_sw, view=c('time_betwe', 'count_points_reburn'), n.grid=50, theta=30, phi=32, zlab="", too.far=0.1)+title("southwest")

summary(fit3_ca)
summary(fit3_nm)
summary(fit3_sw) #*timexsize interaction
summary(fit3_wm) #*timexsize interaction

cor(data_lowmod_wm$erc_perc, data_lowmod_wm$count_points_reburn)
```

### Predict

>how to determine extreme vs. normal fire weather? using our data or local values? What cut offs to use? Should these be ecoregion specific?

```{r}
#create prediction dfs with with 3 values for weather and all values for time between
# Explore predictor space to help determine values for weather vars 
par(mfrow = c(2, 2))
plot(data_lowmod_ca$vpd_perc, data_lowmod_ca$erc_perc)
abline(v = 0.97, h = 0.97, col = "red")


plot(data_lowmod_ca$vpd_perc, data_lowmod_ca$vs_perc)
abline(v = 0.97, h = 0.97, col = "red")

plot(data_lowmod_ca$vs_perc, data_lowmod_ca$erc_perc)
abline(v = 0.97, h = 0.97, col = "red")

#western MTs
par(mfrow = c(2, 2))
plot(data_lowmod_wm$vpd_perc, data_lowmod_wm$erc_perc)
abline(v = 0.97, h = 0.97, col = "red")

plot(data_lowmod_wm$vpd_perc, data_lowmod_wm$vs_perc)
abline(v = 0.97, h = 0.97, col = "red")

plot(data_lowmod_wm$vs_perc, data_lowmod_wm$erc_perc)
abline(v = 0.97, h = 0.97, col = "red")

#western MTs
par(mfrow = c(2, 2))
plot(data_lowmod_nm$vpd_perc, data_lowmod_nm$erc_perc)
abline(v = 0.97, h = 0.97, col = "red")

plot(data_lowmod_nm$vpd_perc, data_lowmod_nm$vs_perc)
abline(v = 0.97, h = 0.97, col = "red")

plot(data_lowmod_nm$vs_perc, data_lowmod_nm$erc_perc)
abline(v = 0.97, h = 0.97, col = "red")

#southwest 
par(mfrow = c(2, 2))
plot(data_lowmod_sw$vpd_perc, data_lowmod_sw$erc_perc)
abline(v = 0.97, h = 0.97, col = "red")

plot(data_lowmod_sw$vpd_perc, data_lowmod_sw$vs_perc)
abline(v = 0.97, h = 0.97, col = "red")
plot(data_lowmod_sw$vs_perc, data_lowmod_sw$erc_perc)
abline(v = 0.97, h = 0.97, col = "red")
```

Explore predictor space for climate vars
```{r}
# Explore predictor space to help determine values for weather vars 
hotdry = data_lowmod_sw %>% filter(PRISM_tmea >= quantile(PRISM_tmea, 0.75) &
                                     PRISM_ppt_ <= quantile(PRISM_ppt_, 0.25))
hist(hotdry$time_betwe)
quantile(hotdry$time_betwe, .90)

warmwet = data_lowmod_nm %>% filter(PRISM_tmea >= quantile(PRISM_tmea, 0.5) &
                                     PRISM_ppt_ >= quantile(PRISM_ppt_, 0.75))


par(mfrow = c(2, 2))
plot(data_lowmod_ca$AET, data_lowmod_ca$PRISM_ppt_)
abline(v = quantile(data_lowmod_ca$AET, 0.75), h = quantile(data_lowmod_ca$PRISM_ppt_, 0.75), col = "blue")
abline(v = quantile(data_lowmod_ca$AET, 0.25), h = quantile(data_lowmod_ca$PRISM_ppt_, 0.25), col = "red")



plot(data_lowmod_ca$AET, data_lowmod_ca$PRISM_tmea)
abline(v = quantile(data_lowmod_ca$AET, 0.75), h = quantile(data_lowmod_ca$PRISM_tmea, 0.25), col = "blue")
abline(v = quantile(data_lowmod_ca$AET, 0.25), h = quantile(data_lowmod_ca$PRISM_tmea, 0.75), col = "red")
abline(v = quantile(data_lowmod_ca$AET, 0.75), h = quantile(data_lowmod_ca$PRISM_tmea, 0.75), col = "green")


plot(data_lowmod_ca$PRISM_tmea, data_lowmod_ca$PRISM_ppt_)
abline(v = quantile(data_lowmod_ca$PRISM_tmea, 0.25), h = quantile(data_lowmod_ca$PRISM_ppt_, 0.75), col = "blue")
abline(v = quantile(data_lowmod_ca$PRISM_tmea, 0.75), h = quantile(data_lowmod_ca$PRISM_ppt_, 0.25), col = "red")
abline(v = quantile(data_lowmod_ca$PRISM_tmea, 0.75), h = quantile(data_lowmod_ca$PRISM_ppt_, 0.75), col = "green")



par(mfrow = c(2, 2))
plot(data_lowmod_nm$AET, data_lowmod_nm$PRISM_ppt_)
abline(v = quantile(data_lowmod_nm$AET, 0.75), h = quantile(data_lowmod_nm$PRISM_ppt_, 0.75), col = "blue")
abline(v = quantile(data_lowmod_nm$AET, 0.25), h = quantile(data_lowmod_nm$PRISM_ppt_, 0.25), col = "red")



plot(data_lowmod_nm$AET, data_lowmod_nm$PRISM_tmea)
abline(v = quantile(data_lowmod_nm$AET, 0.75), h = quantile(data_lowmod_nm$PRISM_tmea, 0.25), col = "blue")
abline(v = quantile(data_lowmod_nm$AET, 0.25), h = quantile(data_lowmod_nm$PRISM_tmea, 0.75), col = "red")
abline(v = quantile(data_lowmod_nm$AET, 0.75), h = quantile(data_lowmod_nm$PRISM_tmea, 0.75), col = "green")


plot(data_lowmod_nm$PRISM_tmea, data_lowmod_nm$PRISM_ppt_)
abline(v = quantile(data_lowmod_nm$PRISM_tmea, 0.25), h = quantile(data_lowmod_nm$PRISM_ppt_, 0.75), col = "blue")
abline(v = quantile(data_lowmod_nm$PRISM_tmea, 0.75), h = quantile(data_lowmod_nm$PRISM_ppt_, 0.25), col = "red")
# abline(v = quantile(data_lowmod_nm$PRISM_tmea, 0.75), h = quantile(data_lowmod_nm$PRISM_ppt_, 0.75), col = "green")


```


```{r}
#prediction df with most variables set to mean = 0
preds_dfw_func = function(df, fit){
  df_w97 = data.frame(count_burn = 0, 
                       # AET = 0, 
                       PRISM_ppt_ = 0, PRISM_tmea = 0,
                       cbi_initial = 0, heat_load = 0, TPI_1024 = 0,
                      # afg_rebrn = 0, pfg_rebrn = 0,
                       #set weather variables to 3rd quantile value by ecoregion
                       vpd_perc = 0.97,
                       erc_perc = 0.97,
                       # vs_02_21 = quantile(df$vs_02_21, 0.95),
                       vs_perc = .50,
                       #set time between fires to full range 1-25 years
                       time_betwe = seq(0.1, 3.6, by = .1),
                       weather = "97perc",
                       #control for lat long
                       lat = mean(df$lat),
                       long = mean(df$long))
  df_w90 = data.frame(count_burn = 0, 
                       # AET = 0, 
                       PRISM_ppt_ = 0, PRISM_tmea = 0,
                       cbi_initial = 0, heat_load = 0, TPI_1024 = 0,
                      # afg_rebrn = 0, pfg_rebrn = 0,
                       #set weather variables to mean 
                       vpd_perc = .90, erc_perc = .90, 
                       vs_perc = .50,
                       #set time between fires to full range 1-25 years
                       time_betwe = seq(0.1, 3.6, by = .1),
                      weather = "90perc",
                       #control for lat long
                       lat = mean(df$lat),
                       long = mean(df$long))
  df_w80 = data.frame(count_burn = 0, 
                       # AET = 0, 
                       PRISM_ppt_ = 0, PRISM_tmea = 0,
                       cbi_initial = 0, heat_load = 0, TPI_1024 = 0,
                      # afg_rebrn = 0, pfg_rebrn = 0,
                       #set weather variables to 1st quantile value  
                       vpd_perc = .8,
                       erc_perc = .8,
                       # vs_perc = quantile(df$vs_perc, 0.25),
                       vs_perc = 0.5,
                       #set time between fires to full range 1-25 years
                       time_betwe = seq(0.1, 3.6, by = .1), 
                      weather = "80perc",
                       #control for lat long
                       lat = mean(df$lat),
                       long = mean(df$long))
  
  data_w = rbind(df_w97, df_w80, df_w90)
  
  #predict to new data
  p = predict.gam(fit, newdata = data_w, se.fit = TRUE)
  
  #add predictions to df for plotting
  data_w$cbi_reburn = p$fit
  data_w$upr = p$fit + (2 * p$se.fit)
  data_w$lwr = p$fit - (2 * p$se.fit)
  
  return(data_w)
}

preds_w_ca <- preds_dfw_func(df = data_lowmod_ca, fit = fit3_ca)
preds_w_nm <- preds_dfw_func(df = data_lowmod_nm, fit = fit3_nm)
preds_w_sw <- preds_dfw_func(df = data_lowmod_sw, fit = fit3_sw)
preds_w_wm <- preds_dfw_func(df = data_lowmod_wm, fit = fit3_wm)
```

climate predictions
```{r}
# #find west wide climate quantiles
# precip75 = quantile(data_lowmod$PRISM_ppt_, 0.75)


#prediction df with variables set to mean = 0
preds_dfc_func = function(df, fit){
  #cool wet - high productivity
  df_coolwet = data.frame(count_burn = 0, 
                        #set climate vars
                       # AET = quantile(df$AET, 0.75), 
                       PRISM_ppt_ = quantile(df$PRISM_ppt_, 0.75),
                       PRISM_tmea = quantile(df$PRISM_tmea, 0.25),
                        #control for other vars - mean
                       cbi_initial = 0, heat_load = 0, TPI_1024 = 0,
                       vpd_perc = .9, erc_perc = .9,vs_perc = .5,
                       # afg_rebrn = 0, pfg_rebrn = 0,
                       #set time between fires to full range 1-25 years
                       time_betwe = seq(0.1, 3.6, by = .1),
                       climate = "cool/wet",
                       #control for lat long
                       lat = mean(df$lat),
                       long = mean(df$long))
  #all vars at mean
  df_mod = data.frame(count_burn = 0, 
                       # AET = 0, 
                       PRISM_ppt_ = 0, PRISM_tmea = 0,
                       cbi_initial = 0, heat_load = 0, TPI_1024 = 0,
                       #set weather variables to mean 
                       vpd_perc = .9, erc_perc = .9,vs_perc = .5,
                      # afg_rebrn = 0, pfg_rebrn = 0,
                       #set time between fires to full range 1-25 years
                       time_betwe = seq(0.1, 3.6, by = .1),
                      climate = "mean",
                       #control for lat long
                       lat = mean(df$lat),
                       long = mean(df$long))
  
  #hot dry - low productivity
  df_hotdry = data.frame(count_burn = 0, 
                        #set climate vars
                       # AET = quantile(df$AET, 0.25), 
                       PRISM_ppt_ = quantile(df$PRISM_ppt_, 0.25),
                       PRISM_tmea = quantile(df$PRISM_tmea, 0.75),
                        #control for other vars - mean
                       cbi_initial = 0, heat_load = 0, TPI_1024 = 0,
                       vpd_perc = .9, erc_perc = .9,vs_perc = .5,
                       # afg_rebrn = 0, pfg_rebrn = 0,
                       #set time between fires to full range 1-25 years
                       time_betwe = seq(0.1, 3.6, by = .1),
                       climate = "hot/dry",
                       #control for lat long
                       lat = mean(df$lat),
                       long = mean(df$long))
  
    #hot dry - low productivity
  df_warmwet = data.frame(count_burn = 0, 
                        #set climate vars
                       # AET = quantile(df$AET, 0.25), 
                       PRISM_ppt_ = quantile(df$PRISM_ppt_, 0.75),
                       PRISM_tmea = quantile(df$PRISM_tmea, 0.50),
                        #control for other vars - mean
                       cbi_initial = 0, heat_load = 0, TPI_1024 = 0,
                       vpd_perc = .9, erc_perc = .9,vs_perc = .5,
                       # afg_rebrn = 0, pfg_rebrn = 0,
                       #set time between fires to full range 1-25 years
                       time_betwe = seq(0.1, 3.6, by = .1),
                       climate = "warm/wet",
                       #control for lat long
                       lat = mean(df$lat),
                       long = mean(df$long))
  
  
  data_c = rbind(df_coolwet, df_hotdry, df_warmwet, df_mod)
  
  #predict to new data
  p = predict.gam(fit, newdata = data_c, se.fit = TRUE)
  
  #add predictions to df for plotting
  data_c$cbi_reburn = p$fit
  data_c$upr = p$fit + (2 * p$se.fit)
  data_c$lwr = p$fit - (2 * p$se.fit)
  return(data_c)
}

preds_c_ca <- preds_dfc_func(df = data_lowmod_ca, fit = fit3_ca)
preds_c_nm <- preds_dfc_func(df = data_lowmod_nm, fit = fit3_nm)
preds_c_sw <- preds_dfc_func(df = data_lowmod_sw, fit = fit3_sw)
preds_c_wm <- preds_dfc_func(df = data_lowmod_wm, fit = fit3_wm)
```

#### Plot predictions

plot interaction between weather and time between fires
```{r}
library(gridExtra)

pca = ggplot(data = preds_w_ca, aes(x = time_betwe, y = cbi_reburn, color = weather)) +
         geom_line(size = 1.05) +
         geom_rug(alpha = .3, position = "jitter", length = unit(0.05, "npc")) +
           geom_ribbon(aes(ymin = lwr, ymax = upr, fill = weather), alpha = 0.1, colour = NA)+
         theme_bw() +
        scale_color_manual(values = c("lightseagreen", "sienna1", "tomato3"))+
    scale_fill_manual(values = c("lightseagreen", "sienna1", "tomato3"))+
  ylim(0.5, 3)+
  ggtitle("California coast")

psw = ggplot(data = preds_w_sw, aes(x = time_betwe, y = cbi_reburn, color = weather)) +
         geom_line(size = 1.05) +
           geom_rug(alpha = .3, position = "jitter", length = unit(0.05, "npc")) +
         geom_ribbon(aes(ymin = lwr, ymax = upr, fill = weather), alpha = 0.1, colour = NA)+
         theme_bw()+
        scale_color_manual(values = c("lightseagreen", "sienna1", "tomato3"))+
    scale_fill_manual(values = c("lightseagreen", "sienna1", "tomato3"))+
    ylim(0.5, 3)+
  ggtitle("Southwest")

pnm = ggplot(data = preds_w_nm, aes(x = time_betwe, y = cbi_reburn, color = weather)) +
         geom_line(size = 1.05) +
           geom_rug(alpha = .3, position = "jitter", length = unit(0.05, "npc")) +
           geom_ribbon(aes(ymin = lwr, ymax = upr, fill = weather), alpha = 0.1, colour = NA)+
         theme_bw()+
        scale_color_manual(values = c("lightseagreen", "sienna1", "tomato3"))+
    scale_fill_manual(values = c("lightseagreen", "sienna1", "tomato3"))+
  ylim(0.5, 3)+
  ggtitle("Northern mountains")

pwm = ggplot(data = preds_w_wm, aes(x = time_betwe, y = cbi_reburn, color = weather)) +
         geom_line(size = 1.05) +
           geom_rug(alpha = .3, position = "jitter", length = unit(0.05, "npc")) +
           geom_ribbon(aes(ymin = lwr, ymax = upr, fill = weather), alpha = 0.1, colour = NA)+
         theme_bw()+
        scale_color_manual(values = c("lightseagreen", "sienna1", "tomato3"))+
    scale_fill_manual(values = c("lightseagreen", "sienna1", "tomato3"))+
  ylim(0.5, 3)+
  ggtitle("Western mountains")

grid.arrange(pca, psw, pnm, pwm, nrow= 2, ncol=2)
```

plot interaction between climate/ productivity and time between fires
```{r}
pca = ggplot(data = preds_c_ca, aes(x = time_betwe, y = cbi_reburn, color = climate)) +

    ylim(0.5, 3)+
            geom_line(size = 1.01) +
             geom_ribbon(aes(ymin = lwr, ymax = upr, fill = climate), alpha = 0.1, colour = NA)+
         theme_bw() +
      scale_color_manual(values = c("#247ba0", "sienna1", "#21272A", "#76B041"))+
    scale_fill_manual(values = c("#247ba0", "sienna1", "#21272A", "#76B041"))+
  ggtitle("California coast")

psw = ggplot(data = preds_c_sw, aes(x = time_betwe, y = cbi_reburn, color = climate)) +

    ylim(0.5, 3)+
         geom_line(size = 1.01) +
             geom_ribbon(aes(ymin = lwr, ymax = upr, fill = climate), alpha = 0.1, colour = NA)+
         theme_bw()+
      scale_color_manual(values = c("#247ba0", "sienna1", "#21272A", "#76B041"))+
    scale_fill_manual(values = c("#247ba0", "sienna1", "#21272A", "#76B041"))+
  ggtitle("Southwest")

pnm = ggplot(data = preds_c_nm, aes(x = time_betwe, y = cbi_reburn, color = climate)) +

    ylim(0.5, 3)+
         geom_line(size = 1.01) +
             geom_ribbon(aes(ymin = lwr, ymax = upr, fill = climate), alpha = 0.1, colour = NA)+
         theme_bw()+
      scale_color_manual(values = c("#247ba0", "sienna1", "#21272A", "#76B041"))+
    scale_fill_manual(values = c("#247ba0", "sienna1", "#21272A", "#76B041"))+
  ggtitle("Northern mountains")

pwm = ggplot() +
    ylim(0.5, 3)+
         geom_line(data = preds_c_wm, aes(x = time_betwe, y = cbi_reburn, color = climate), size = 1.01) +
             geom_ribbon(data = preds_c_wm, aes(x = time_betwe, ymin = lwr, ymax = upr, fill = climate), alpha = 0.1, colour = NA)+
         theme_bw()+
      scale_color_manual(values = c("#247ba0", "sienna1", "#21272A", "#76B041"))+
    scale_fill_manual(values = c("#247ba0", "sienna1", "#21272A", "#76B041"))+
  ggtitle("Western mountains")


grid.arrange(pca, psw, pnm, pwm, nrow= 2, ncol=2)



```

```{r}
#When you use vis.gam() varying x and cov1 you are getting a plot of the expected response from the whole model s(x) + te(x, cov1) + other_stuff, when you vary input values x and cov1 while holding other_stuff at representative (or user supplied) values.
plot.gam(fit3_ca, view=c('cbi_initial'), n.grid=50, theta=35, phi=32, zlab="", too.far=0.1)
plot.gam(fit3_ca, view=c('time_betwe'), n.grid=50, theta=35, phi=32, zlab="", too.far=0.1)

vis.gam(fit3_nm, view=c('time_betwe', 'PRISM_tmea'), n.grid=50, theta=150, phi=32, zlab="", too.far=0.1)
vis.gam(fit3_nm, view=c('time_betwe', 'PRISM_ppt_'), n.grid=50, theta=35, phi=32, zlab="", too.far=0.1)
vis.gam(fit2_nm, view=c('time_betwe', 'AET'), n.grid=50, theta=50, phi=32, zlab="", too.far=0.1)


vis.gam(fit_wm, view=c('time_betwe', 'AET'), n.grid=50, theta=35, phi=32, zlab="", too.far=0.1)
vis.gam(fit_sw, view=c('time_betwe', 'AET'), n.grid=50, theta=35, phi=32, zlab="", too.far=0.1)

plot.gam(fit_ca, view=c('vpd_02_21', 'erc_02_21', 'vs_02_21'))

p = predict.gam(fit_ca, newdata = mm)

#extreme weather -
erc_high = summary(data_lowmod$AET)




preds_1 <- predict_gam(fit_ca, length_out = 100)
                       
plot(preds_1, "time_betwe")


```

density plots
```{r}
library(ggridges)
ggplot(data = data_lowmod, aes(x = cbi_initial, y = ecoregion, fill = ecoregion)) +
  geom_density_ridges()

ggplot(data = data_lowmod, aes(x = time_betwe*10, y = ecoregion, fill = ecoregion)) +
  geom_density_ridges()
```


-



--------------------------------------------------------------------------------

## Sparse modeling with LASSO
```{r}
library(glmnet)

#scale numeric predictor variables for LASSO
data_lowmod_logit = data_lowmod %>% 
  mutate(cbi_reburn_logit = logit(normalize(cbi_reburn))) %>%
  # mutate(across(heat_load:cbi_initial, base::scale)) %>%
  data.frame()

data_lowmod_scale = scale(data_lowmod_logit[,1:21], scale = TRUE, center = TRUE)
data_lowmod_scale = cbind(data_lowmod_scale, data_lowmod_logit[,22:33])

#create model matrix
mm = model.matrix(~ cbi_initial*ecoregion + I(cbi_initial^2)*ecoregion +
                    erc_02_21*ecoregion + I(erc_02_21^2)*ecoregion + fm100_02_2*ecoregion + I(fm100_02_2^2)*ecoregion + fm1000_02_*ecoregion + I(fm1000_02_^2)*ecoregion + th_02_21*ecoregion + I(th_02_21^2)*ecoregion + vpd_02_21*ecoregion + I(vpd_02_21^2)*ecoregion + vs_02_21*ecoregion + I(vs_02_21^2)*ecoregion + 
                    heat_load*ecoregion + I(heat_load^2)*ecoregion + TPI_1024*ecoregion + I(TPI_1024^2)*ecoregion + 
                    AET*ecoregion + I(AET^2)*ecoregion + PRISM_ppt_*ecoregion + I(PRISM_ppt_^2)*ecoregion + PRISM_tmea*ecoregion + I(PRISM_tmea^2)*ecoregion + PRISM_vpdm*ecoregion + I(PRISM_vpdm^2)*ecoregion + 
                    count_burn*ecoregion + time_betwe*ecoregion + I(time_betwe^2)*ecoregion + count_burn*ecoregion + time_betwe*ecoregion + I(time_betwe^2)*ecoregion + 
                    ndvi*ecoregion + I(ndvi^2)*ecoregion + shrub_rebrn*ecoregion + I(shrub_rebrn^2)*ecoregion + tree_reburn*ecoregion + I(tree_reburn^2)*ecoregion + 
                    postmanage10*ecoregion + premanage10*ecoregion + 
                    ecoregion +
                    AET*time_betwe + I(AET^2)*I(time_betwe^2) + I(AET^2)*time_betwe + AET*I(time_betwe^2) + 
         PRISM_ppt_*time_betwe + I(PRISM_ppt_^2)*I(time_betwe^2) + I(PRISM_ppt_^2)*time_betwe + PRISM_ppt_*I(time_betwe^2) +
          PRISM_tmea*time_betwe + I(PRISM_tmea^2)*I(time_betwe^2) + I(PRISM_tmea^2)*time_betwe + PRISM_tmea*I(time_betwe^2) +
           PRISM_vpdm*time_betwe + I(PRISM_vpdm^2)*I(time_betwe^2) + I(PRISM_vpdm^2)*time_betwe + PRISM_vpdm*I(time_betwe^2), data = data_lowmod_scale)

#fit LASSO
fit = glmnet(mm, df$cbi_reburn, alpha = 0.5) #minimize sum of squares under condition that sum of absolute values of coef needs to be under some value #how to keep some vars out of LASSO? Add variables in after? 
#alpha = 0.5 half penalty comes from ridge regression and half comes from lasso. 

#plot fit
plot(fit, label = TRUE) #L1 norm = sum of absolute values of coefficients 




#cross validate
cvfit <- cv.glmnet(mm_ca, data_lowmod_scale$cbi_reburn, )
plot(cvfit)

# print(fit$beta)
print(cvfit$lambda.1se)

fit1se = glmnet(mm_ca, data_lowmod_ca$cbi_reburn, lambda = cvfit$lambda.1se) #minimize sum of squares under condition that sum of absolute values of coef needs to be under some value #how to keep some vars out of LASSO? Add variables in after? 

```

fit separate lasso models for each ecoregion
```{r}
#function to fit sparse models and choose model with lambda = 1 se

sparsemodel = function(df){
  
  #define model matrix - removed fm100 & fm1000, reburn shrub cover, ndvi, and management 
  mm = model.matrix(~ cbi_initial + I(cbi_initial^2) +
                    erc_02_21 + I(erc_02_21^2) + + th_02_21 + I(th_02_21^2) + vpd_02_21 + I(vpd_02_21^2) + vs_02_21 + I(vs_02_21^2) + 
                    heat_load + I(heat_load^2) + TPI_1024 + I(TPI_1024^2) + 
                    AET + I(AET^2) + PRISM_ppt_ + I(PRISM_ppt_^2) + PRISM_tmea + I(PRISM_tmea^2) + PRISM_vpdm + I(PRISM_vpdm^2) + 
                    count_burn + time_betwe + I(time_betwe^2) + count_burn + time_betwe + I(time_betwe^2) 
                    + tree_reburn + I(tree_reburn^2) + 
              
                    AET*time_betwe + I(AET^2)*I(time_betwe^2) + I(AET^2)*time_betwe + AET*I(time_betwe^2) + 
         PRISM_ppt_*time_betwe + I(PRISM_ppt_^2)*I(time_betwe^2) + I(PRISM_ppt_^2)*time_betwe + PRISM_ppt_*I(time_betwe^2) +
          PRISM_tmea*time_betwe + I(PRISM_tmea^2)*I(time_betwe^2) + I(PRISM_tmea^2)*time_betwe + PRISM_tmea*I(time_betwe^2) +
           PRISM_vpdm*time_betwe + I(PRISM_vpdm^2)*I(time_betwe^2) + I(PRISM_vpdm^2)*time_betwe + PRISM_vpdm*I(time_betwe^2), 
         data = df)
  
  #fit LASSO
  fit = glmnet(mm, df$cbi_reburn_logit, alpha = 1) #minimize sum of squares under condition that sum of absolute values of coef needs to be under some value #how to keep some vars out of LASSO? Add variables in after? 
  #alpha=1 is the lasso penalty, and alpha=0 the ridge penalty.
  
  #cross validate
  cvfit <- cv.glmnet(mm, df$cbi_reburn_logit)
  
  #fit with lambda 1 se
  fit1se = glmnet(mm, df$cbi_reburn_logit, lambda = cvfit$lambda.1se)
  fit2se = glmnet(mm, df$cbi_reburn_logit, lambda = cvfit$lambda.1se*2)
  fit3se = glmnet(mm, df$cbi_reburn_logit, lambda = cvfit$lambda.1se*3)

  output_list = list("fit" = fit, "cvfit" = cvfit, "fit1se" = fit1se$beta, "fit2se" = fit2se$beta, "fit3se" = fit3se$beta)
  # return(output_list)

}

fit_ca = sparsemodel(data_lowmod_ca)
fit_nm = sparsemodel(data_lowmod_nm)
fit_sw = sparsemodel(data_lowmod_sw)
fit_wm = sparsemodel(data_lowmod_wm)

plot(fit_ca$cvfit)
fit_ca$fit2se
# fit_ca$fit1se

fit_ca = as.data.frame(as.matrix(fit_ca$fit3se)) %>% rownames_to_column("var")
fit_nm = as.data.frame(as.matrix(fit_nm$fit3se))
fit_sw = as.data.frame(as.matrix(fit_sw$fit3se))
fit_wm = as.data.frame(as.matrix(fit_wm$fit3se))

fit_mods = bind_cols(fit_ca, fit_nm, fit_sw, fit_wm)
colnames(fit_mods) = c("var", "fit_ca", "fit_nm", "fit_sw", "fit_wm")

fit_mods = fit_mods %>% pivot_longer(fit_ca:fit_wm, names_to = "eco", values_to = "estimates")

ggplot(fit_mods,
       aes(x = estimates, y = var, color = eco)) +
  geom_point(stat = "identity", size = 2) +
  theme_bw(13)
```


Fit LASSO with GAMs
```{r}
# library(plsmselect)
library(gamsel) # https://arxiv.org/abs/1506.03850
# https://www.r-bloggers.com/2019/11/an-unofficial-vignette-for-the-gamsel-package/


#lump variables by category
climate = c('AET', 'PRISM_ppt_', 'PRISM_tmea', 'PRISM_vpdm')
fire_hist = c('cbi_initial', 'time_betwe') 
weather = c('erc_02_21', 'th_02_21', 'vpd_02_21', 'vs_02_21') #remove fm100 if keeping erc because they are highly correlated >.9
topo = c('heat_load', 'TPI_1024')
fuels = c('ndvi', 'tree_reburn') #remove shrubs
manage = c('postmanage10', 'premanage10') #remove rows with postmanage from dataset for initial full analysis
eco = 'ecoregion'

#define interactions
data_lowmod_scale = data_lowmod_scale %>% 
  mutate(AET_int = AET*time_betwe,
         precip_int = PRISM_ppt_*time_betwe,
         tmean_int = PRISM_tmea*time_betwe,
         vpd_int = PRISM_vpdm*time_betwe)

ints = c('AET_int', 'precip_int', 'tmean_int', 'vpd_int')

#vars to include in gams
vars = c(climate, fire_hist, weather, topo, fuels, ints)
#create matrix for gams with relevant variables
x = data_lowmod_scale %>% 
  dplyr::select(any_of(vars)) %>% as.matrix()

y = data_lowmod_scale$cbi_reburn_logit
y = data_lowmod$cbi_reburn

```

fit gamsel - chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://cran.r-project.org/web/packages/gamsel/gamsel.pdf 


```{r}
#fit gamsel
fit <- gamsel(x, y, df = 5, degree = 8) #

#tuning gamsel: 
#gamsel has a tuning parameter gamma which is between 0 and 1. Smaller values of gamma penalize the linear components less than the non-linear components, resulting in more linear components for the fitted model. The default value is gamma = 0.4.

# By default, each variable is given m_j = 10 basis functions. This can be modified with the degrees option, and this value can differ from variable to variable (to allow for this, pass a vector of length equal to the number of variables to the degrees option).
# 
# By default, the maximum degrees of freedom for each variable is 5. This can be modified with the dfs option, with larger values allowing more â€œwigglyâ€ fits. Again, this value can differ from variable to variable.

fit #Printing the returned gamsel object tells us how many features, linear components and non-linear components were included in the model for each lambda value respectively. It also shows the fraction of null deviance explained by the model and the lambda value for that model.


summary(fit, label = TRUE)
#plot fits - By default, plot() gives the fitted functions for the last value of the lambda key in fit, and gives plots for all the features.  The user can specify the index of the lambda value to show using the index option:


plot(fit, x, index = 19)

```

K-fold cross-validation for gamsel
```{r}
cv = cv.gamsel(x, y, nfolds = 5, parallel = TRUE)
#gamma=.4 is assumed by default
plot(cv)


#fit gamsel with defined lambda
fit1se <- gamsel(x, y, df = 5, degree = 8, lambda = cv$lambda.1se) 
fit1se$betas

plot(fit, newx =x, index = cv$index.1se)

i = getActive(fit, index = 19)
colnames(x[,i$l19])

```


Plot Predictions

Predictions from this model can be obtained by using the predict method of the gamsel() function output: each column gives the predictions for a value of lambda.

type = "terms" gives a matrix of fitted functions, with as many columns as there are variables. This can be useful for understanding the effect that each variable has on the response. Note that what is returned is a 3-dimensional array!

```{r}
library(boot)
indiv_fits = predict(fit, x[, ], index = 19, type = "terms") #index = model number
predict(fit, x[, ], index = 19, type = "nonzero")

aet = seq(-2.5,4,length.out = 100)
other = rep(0,100)

newdat = matrix(c(aet,rep(other,17)),ncol = 18)
aet_fit = predict(fit, newdat, index = 19, type = "terms")

plot(aet, aet_fit[,,1])

# plot(x[1:10000, 6], y[1:10000])
# par(mfrow=c(2,5)) 
plot(x[, 1], indiv_fits[, , 1], xlab = "AET", col = 'red', ylab = "effect of reburn cbi")
# plot(x[1:10000, 3], indiv_fits[, , 3], xlab = "PRISM_tmea", col = 'red', ylab = "logit reburn cbi")
# plot(x[1:10000, 5], indiv_fits[, , 5], xlab = "cbi_initial", col = 'red', ylab = "logit reburn cbi")
# plot(x[1:10000, 6], indiv_fits[, , 6], xlab = "time_betwe", col = 'red', ylab = "logit reburn cbi")
# plot(x[1:10000, 8], indiv_fits[, , 8], xlab = "th_02_21", col = 'red', ylab = "logit reburn cbi")
# plot(x[1:10000, 9], indiv_fits[, , 9], xlab = "tvpd_02_21", col = 'red', ylab = "logit reburn cbi")
# plot(x[1:10000, 10], indiv_fits[, , 10], xlab = "vs_02_21", col = 'red', ylab = "logit reburn cbi")
# plot(x[1:10000, 12], indiv_fits[, , 12], xlab = "TPI_1024", col = 'red', ylab = "logit reburn cbi")
# plot(x[1:10000, 13], indiv_fits[, , 13], xlab = "ndvi", col = 'red', ylab = "logit reburn cbi")
# plot(x[1:10000, 15], indiv_fits[, , 15], xlab = "AET*time between", col = 'red', ylab = "logit reburn cbi")
```

GAM lasso with plsmselect https://cran.r-project.org/web/packages/plsmselect/vignettes/plsmselect.html 
```{r}
library(plsmselect)
data_lowmod_scale$X <- model.matrix( ~ count_burn + cbi_initial,
                        data=data_lowmod_scale)[,-1]

gfit = gamlasso(cbi_reburn_logit ~ X +
                  s(AET, k = 5, bs = "ts") +
                  s(PRISM_ppt_, k = 5, bs = "ts") +
                  s(PRISM_tmea, k = 5, bs = "ts") +
                  # s(PRISM_vpdm, k = 5, bs = "ts") +
                  # s(cbi_initial, k = 5, bs = "ts") + # fitting this as a linear term instead
                  s(time_betwe, k = 5, bs = "ts") +
                  s(erc_02_21, k = 5, bs = "ts") +
                  # s(th_02_21, k = 5, bs = "ts") +
                  s(vpd_02_21, k = 5, bs = "ts") +
                  s(vs_02_21, k = 5, bs = "ts") +
                  s(heat_load, k = 5, bs = "ts") +
                  s(TPI_1024, k = 5, bs = "ts") +
                  # s(tree_reburn, k = 5, bs = "ts") +
                  s(time_betwe, by = AET, k = 5, bs = "ts") +
                  s(time_betwe, by = PRISM_ppt_, k = 5, bs = "ts") +
                  s(time_betwe, by = PRISM_tmea, k = 5, bs = "ts"),
                data = data_lowmod_scale,
                linear.penalty = "l1",
                smooth.penalty = "l1",
                seed = 1)

summary(gfit)
plot(gfit$cv.glmnet)

summary(gfit$cv.glmnet$lambda.1se)

plot(gfit$gam, pages=1)
plot(data_lowmod_scale$cbi_reburn_logit, predict(gfit), xlab = "Observed values", ylab = "Fitted Values")
```



#lump variables by category
climate = c('AET', 'PRISM_ppt_', 'PRISM_tmea', 'PRISM_vpdm')
fire_hist = c('cbi_initial', 'time_betwe') 
weather = c('erc_02_21', 'fm100_02_2', 'fm1000_02_', 'th_02_21', 'vpd_02_21', 'vs_02_21') #remove fm100 if keeping erc because they are highly correlated >.9
topo = c('heat_load', 'TPI_1024')
fuels = c('ndvi', 'shrub_rebrn', 'tree_reburn')
manage = c('postmanage10', 'premanage10') #remove rows with postmanage from dataset for initial full analysis
eco = 'ecoregion'



>logistic model to account for bounded response cbi reburn?
> decide what to do with correlated variables? change alpha to include more correlated variables or choose some based on prior knowledge
> weird relationships with management (Separate analysis?)




## GAMs

Variable selection for GAMs - 
> based on prediction rather than sig.
> could use RF importance score - how to best generate? (RF: rm pointid, fire years, combine facts, change facts 0s)
> 

Testing model fit:
>tileing > random selection
>change 

```{r}
library(mgcv)

g1 <- bam(cbi_reburn ~ s(AET) + s(time_betwe, by = ecoregion) + s(time_betwe, AET) +
    s(vpd_02_21) + s(th_02_21) + s(fm_02_21) + s(fm100_02_2) + s(vs_02_21) + s(TPI_1024) + s(cbi_initial) + ecoregion, 
    data = train, 
    method = "REML")
g1
summary(g1)
k.check(g1)
gam.check(g1)

g2 <- bam(cbi_reburn ~ s(time_betwe, by = ecoregion),
    data = train, 
    method = "REML")

g2 <- bam(cbi_reburn ~ s(time_betwe, by = ecoregion),
    data = train, 
    method = "REML")

g3 <- bam(cbi_reburn ~ s(time_betwe, AET),
    data = train, 
    method = "REML")


plot(g1)
vis.gam(g1, view = c("time_betwe", "AET"),
    theta = 50, n.grid = 50, lwd = 0.4)
    
vis.gam(g2, view = c("time_betwe", "ecoregion"),
    theta = 50, n.grid = 50, lwd = 0.4)
    
plot(g2)

summary.gam(g1)

newdata = data.frame(cbi_reburn = seq(0.5,3, length.out = 1000))
p1 = predict(g1, newdata = newdata, type = "response" )
```

Other options for variable selection:
> Lasso prior

>group variable list: (explore correlations )
-weather
-topography (TPI)
-history (time since fire, number of burns, intial cbi, management)
-fuels? (ndvi, tree, shrub)
-climate (AET, PRISM)





-------------------

## Random forests analysis



RF settings
>important to tune the parameters - #trees and max.depth
>look into importance settings
> RF with raw cbi instead of groups

### Random forest in R
```{r}
rf <- ranger(cbi_reburn~., 
             data=train, 
             num.trees = 100,
             max.depth = 8,
             importance = 'impurity') #look into these importance options

rf
```
#### How are the predictions compared to the observed data?
```{r}
library(Metrics)

pred_rf = predict(rf, test)$predictions
rmse(test$cbi_reburn, pred_rf)

test %>% 
  mutate(predicted = predict(rf, test)$predictions) %>% 
  ggplot(aes(predicted, cbi_reburn)) +
  geom_point(colour = "#ff6767", alpha = 0.3) +
  labs(title = "Predicted and observed") +  theme_bw(18)

```



```{r}
#relative importance
sort(importance(rf))

# Prediction wrapper that returns average prediction for each class
pfun <- function(object, newdata) {
  colMeans(predict(object, data = newdata)$predictions)
}

# Partial dependence of probability for each class on cbi reburn
p <- partial(rf, pred.var = c("time_betwe", "AET"), pred.fun = pfun)

ggplot(p, aes(time_betwe, yhat, color = yhat.id)) +
  geom_line() +
  theme(legend.title = element_blank())
```


Extract random sample points by each ecoregion
```{r}
# st_write(data_lowmod, datadir("prelim-outputs/points/data_lowmod.gpkg"))  
# 
# new_df <- data_sub %>% group_by(ecoregion) %>% 
#   slice_sample(n=100) %>% 
#   dplyr::select(pointid, ecoregion, lat, long)
# st_write(new_df, "spatial_points_for_GRIDMET_percentile_extract.shp")
```